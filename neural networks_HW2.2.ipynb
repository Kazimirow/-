{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f80d35a2",
   "metadata": {},
   "source": [
    "Задание 2: Обучить глубокую сверточную сеть на MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18447d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Потери: 0.0788004919886589\n",
      "Эпоха 2, Потери: 0.1029190793633461\n",
      "Эпоха 3, Потери: 0.009792177937924862\n",
      "Эпоха 4, Потери: 0.001862076111137867\n",
      "Эпоха 5, Потери: 0.0012110683601349592\n",
      "Точность модели после 10000 протестированных изображений: 99.1 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# Определение трансформации данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Загрузка датасета\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Определение модели\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1024, 128) # 64 * 4 * 4, после двух сверток и пулингов\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # Выпрямляем вектор для FC слоев\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    for epoch in range(5): # Проходим по датасету 5 раз\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # обнуляем градиенты\n",
    "            output = model(data) # получаем выход модели\n",
    "            loss = criterion(output, target) # расчет потерь\n",
    "            loss.backward() # обратное распространение ошибки\n",
    "            optimizer.step() # обновление весов\n",
    "            \n",
    "        print(f'Эпоха {epoch+1}, Потери: {loss.item()}')\n",
    "\n",
    "train(model, train_loader)\n",
    "\n",
    "# Тестирование модели\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    print(f'Точность модели после 10000 протестированных изображений: {100 * correct / total} %')\n",
    "\n",
    "test(model, test_loader)\n",
    "\n",
    "# Визуализация результатов\n",
    "# Загрузим несколько тестовых изображений\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Выведем оригинальные изображения\n",
    "def imshow(img):\n",
    "    img = img * 0.5 + 0.5  # денормализация\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Выведем несколько изображений\n",
    "imshow(torchvision.utils.make_grid(images[:5]))\n",
    "# Верные метки\n",
    "print('Верные метки: ', ' '.join(f'{labels[j].item()}' for j in range(5)))\n",
    "\n",
    "# Используем модель для предсказаний\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Выведем предсказания\n",
    "print('Предсказания: ', ' '.join(f'{predicted[j].item()}' for j in range(5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1277a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6e156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ff8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
