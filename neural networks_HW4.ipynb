{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "332df1c2",
   "metadata": {},
   "source": [
    "Задание 1: Сравнить LSTM, RNN и GRU на задаче предсказания части речи (качество предсказания, скорость обучения, время инференса модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637e5bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Roadmarshal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Roadmarshal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN model...\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - accuracy: 0.0328 - loss: 2.3823 - val_accuracy: 0.0400 - val_loss: 1.8927\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.0462 - loss: 1.7528 - val_accuracy: 0.0591 - val_loss: 1.4247\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.0642 - loss: 1.2847 - val_accuracy: 0.0722 - val_loss: 1.0205\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.0743 - loss: 0.9002 - val_accuracy: 0.0768 - val_loss: 0.7500\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.0803 - loss: 0.6407 - val_accuracy: 0.0813 - val_loss: 0.5703\n",
      "RNN Accuracy: 8.11%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30s/step\n",
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4s/step - accuracy: 0.0283 - loss: 2.4896 - val_accuracy: 0.0289 - val_loss: 2.2086\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step - accuracy: 0.0334 - loss: 2.1197 - val_accuracy: 0.0423 - val_loss: 1.8659\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - accuracy: 0.0477 - loss: 1.7440 - val_accuracy: 0.0605 - val_loss: 1.3934\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.0648 - loss: 1.2663 - val_accuracy: 0.0702 - val_loss: 0.9756\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.0727 - loss: 0.8656 - val_accuracy: 0.0766 - val_loss: 0.6949\n",
      "LSTM Accuracy: 7.63%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "\n",
      "Training GRU model...\n",
      "Epoch 1/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 5s/step - accuracy: 0.0570 - loss: 2.4632 - val_accuracy: 0.0412 - val_loss: 1.9506\n",
      "Epoch 2/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.0444 - loss: 1.7874 - val_accuracy: 0.0609 - val_loss: 1.3480\n",
      "Epoch 3/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.0658 - loss: 1.2071 - val_accuracy: 0.0722 - val_loss: 0.9069\n",
      "Epoch 4/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.0753 - loss: 0.7907 - val_accuracy: 0.0780 - val_loss: 0.6422\n",
      "Epoch 5/5\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.0814 - loss: 0.5426 - val_accuracy: 0.0831 - val_loss: 0.4722\n",
      "GRU Accuracy: 8.27%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
      "\n",
      "Сравнительные результаты:\n",
      "Model: RNN\n",
      "\tAccuracy: 8.11%\n",
      "\tTraining time: 294.98 seconds\n",
      "\tInference time: 30117.70 ms\n",
      "Model: LSTM\n",
      "\tAccuracy: 7.63%\n",
      "\tTraining time: 583.50 seconds\n",
      "\tInference time: 20722.72 ms\n",
      "Model: GRU\n",
      "\tAccuracy: 8.27%\n",
      "\tTraining time: 568.08 seconds\n",
      "\tInference time: 19248.15 ms\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "\n",
      "Original sentence: This is a simple test\n",
      "Predicted POS tags: ['DET', 'VERB', 'DET', 'ADJ', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, GRU, TimeDistributed, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# Загрузка и подготовка данных\n",
    "sentences = treebank.tagged_sents(tagset='universal')\n",
    "X = [[word for word, tag in sent] for sent in sentences]\n",
    "y = [[tag for word, tag in sent] for sent in sentences]\n",
    "\n",
    "word_tokenizer = Tokenizer(lower=False, oov_token='OOV')  # Токенизатор для слов\n",
    "word_tokenizer.fit_on_texts(X)\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)\n",
    "\n",
    "tag_tokenizer = Tokenizer(lower=False)  # Токенизатор для тегов\n",
    "tag_tokenizer.fit_on_texts(y)\n",
    "y_encoded = tag_tokenizer.texts_to_sequences(y)\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, padding='post')  # Дополнение последовательностей слов\n",
    "y_padded = pad_sequences(y_encoded, padding='post')  # Дополнение последовательностей тегов\n",
    "\n",
    "y_padded = np.expand_dims(y_padded, -1)  # В форме, пригодной для sparse_categorical_crossentropy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_padded, test_size=0.2)\n",
    "\n",
    "input_dim = len(word_tokenizer.word_index) + 1\n",
    "output_dim = 64\n",
    "n_tags = len(tag_tokenizer.word_index) + 1\n",
    "\n",
    "def create_model(model_type):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True),\n",
    "        model_type(64, return_sequences=True),\n",
    "        TimeDistributed(Dense(n_tags, activation=\"softmax\")),\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model_types = {\n",
    "    \"RNN\": SimpleRNN,\n",
    "    \"LSTM\": LSTM,\n",
    "    \"GRU\": GRU,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model_type in model_types.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    model = create_model(model_type)\n",
    "  \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, validation_split=0.1, verbose=1)\n",
    "    training_time = time.time() - start_time\n",
    "  \n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"{name} Accuracy: {accuracy*100:.2f}%\")\n",
    "  \n",
    "    start_time = time.time()\n",
    "    _ = model.predict(X_test[:1])\n",
    "    inference_time = time.time() - start_time\n",
    "  \n",
    "    results[name] = {\"accuracy\": accuracy, \"training_time\": training_time, \"inference_time\": inference_time}\n",
    "\n",
    "# Вывод сравнительных результатов\n",
    "print(\"\\nСравнительные результаты:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"\\tAccuracy: {metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"\\tTraining time: {metrics['training_time']:.2f} seconds\")\n",
    "    print(f\"\\tInference time: {metrics['inference_time']*1000:.2f} ms\")\n",
    "\n",
    "# Пример предсказания\n",
    "sample_test = ['This', 'is', 'a', 'simple', 'test']  # Добавлен пример предложения\n",
    "idx2tag = {value: key for key, value in tag_tokenizer.word_index.items()}\n",
    "sample_test_seq = word_tokenizer.texts_to_sequences([sample_test])\n",
    "# Обратите внимание, что мы используем maxlen=X_test.shape[1], чтобы размерность соответствовала предыдущим предсказаниям модели\n",
    "padded_sample_test = pad_sequences(sample_test_seq, maxlen=X_test.shape[1], padding='post') \n",
    "predictions = model.predict(padded_sample_test)\n",
    "pred_index = np.argmax(predictions, axis=-1)[0]  # Берём первый элемент, поскольку предсказание делается для одного предложения\n",
    "\n",
    "# Улучшение: фильтруем предсказания до длины исходного предложения\n",
    "pred_tags = [idx2tag.get(index) for index in pred_index][:len(sample_test)]  # Учитываем только слова в sample_test\n",
    "\n",
    "print(f'\\nOriginal sentence: {\" \".join(sample_test)}')\n",
    "print(f'Predicted POS tags: {pred_tags}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c8360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
